{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing the necessary packages\nimport pandas as pd\nimport numpy as np\nimport keras\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:32:30.624170Z","iopub.execute_input":"2021-12-06T06:32:30.624568Z","iopub.status.idle":"2021-12-06T06:32:30.627837Z","shell.execute_reply.started":"2021-12-06T06:32:30.624540Z","shell.execute_reply":"2021-12-06T06:32:30.627254Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# load pima indians dataset\ndataset = np.loadtxt(\"../input/prima123/pima-indians-diabetes.data.csv\", delimiter=\",\")","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:32:30.628685Z","iopub.execute_input":"2021-12-06T06:32:30.628902Z","iopub.status.idle":"2021-12-06T06:32:30.660530Z","shell.execute_reply.started":"2021-12-06T06:32:30.628883Z","shell.execute_reply":"2021-12-06T06:32:30.659063Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X = dataset[:,0:8]\ny = dataset[:,8]","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:32:30.661382Z","iopub.execute_input":"2021-12-06T06:32:30.661587Z","iopub.status.idle":"2021-12-06T06:32:30.665913Z","shell.execute_reply.started":"2021-12-06T06:32:30.661565Z","shell.execute_reply":"2021-12-06T06:32:30.664834Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Standardization\na = StandardScaler()\na.fit(X)\nX_standardized = a.transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:32:30.877245Z","iopub.execute_input":"2021-12-06T06:32:30.877503Z","iopub.status.idle":"2021-12-06T06:32:30.882278Z","shell.execute_reply.started":"2021-12-06T06:32:30.877479Z","shell.execute_reply":"2021-12-06T06:32:30.881381Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(X_standardized).describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:32:30.883440Z","iopub.execute_input":"2021-12-06T06:32:30.883760Z","iopub.status.idle":"2021-12-06T06:32:30.922075Z","shell.execute_reply.started":"2021-12-06T06:32:30.883720Z","shell.execute_reply":"2021-12-06T06:32:30.921091Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"#### Tuning of Hyperparameters :- Batch Size and Epochs","metadata":{}},{"cell_type":"code","source":"# Importing the necessary packages\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:32:30.923707Z","iopub.execute_input":"2021-12-06T06:32:30.924010Z","iopub.status.idle":"2021-12-06T06:32:30.929628Z","shell.execute_reply.started":"2021-12-06T06:32:30.923981Z","shell.execute_reply":"2021-12-06T06:32:30.928556Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# create model\ndef create_model():\n    model = Sequential()\n    model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n    model.add(Dense(8, init='uniform', activation='relu'))\n    model.add(Dense(1, init='uniform', activation='sigmoid'))\n    \n    adam=Adam(lr=0.01)\n    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:32:30.930666Z","iopub.execute_input":"2021-12-06T06:32:30.931261Z","iopub.status.idle":"2021-12-06T06:32:30.944461Z","shell.execute_reply.started":"2021-12-06T06:32:30.931231Z","shell.execute_reply":"2021-12-06T06:32:30.943422Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Create the model\nmodel = KerasClassifier(build_fn = create_model,verbose = 0)\n# Define the grid search parameters\nbatch_size = [10,20,40]\nepochs = [10,50,100]\n# Make a dictionary of the grid search parameters\nparam_grid = dict(batch_size = batch_size,epochs = epochs)\n# Build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\ngrid_result = grid.fit(X_standardized,y)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:32:30.946632Z","iopub.execute_input":"2021-12-06T06:32:30.947002Z","iopub.status.idle":"2021-12-06T06:32:31.242400Z","shell.execute_reply.started":"2021-12-06T06:32:30.946974Z","shell.execute_reply":"2021-12-06T06:32:31.239882Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"#### Tuning of Hyperparameters:- Learning rate and Drop out rate","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dropout\n\n# Defining the model\n\ndef create_model(learning_rate,dropout_rate):\n    model = Sequential()\n    model.add(Dense(8,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(4,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = learning_rate)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n\n# Define the grid search parameters\n\nlearning_rate = [0.001,0.01,0.1]\ndropout_rate = [0.0,0.1,0.2]\n\n# Make a dictionary of the grid search parameters\n\nparam_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n\n# Build and fit the GridSearchCV\n\ngrid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\ngrid_result = grid.fit(X_standardized,y)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:32:46.729196Z","iopub.execute_input":"2021-12-06T06:32:46.729494Z","iopub.status.idle":"2021-12-06T06:33:19.160773Z","shell.execute_reply.started":"2021-12-06T06:32:46.729466Z","shell.execute_reply":"2021-12-06T06:33:19.159821Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Summarize the results\nprint('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n  print('{},{} with: {}'.format(mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:33:40.089847Z","iopub.execute_input":"2021-12-06T06:33:40.090134Z","iopub.status.idle":"2021-12-06T06:33:40.097632Z","shell.execute_reply.started":"2021-12-06T06:33:40.090110Z","shell.execute_reply":"2021-12-06T06:33:40.096411Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"#### Tuning of Hyperparameters:- Activation Function and Kernel Initializer","metadata":{}},{"cell_type":"code","source":"# Defining the model\n\ndef create_model(activation_function,init):\n    model = Sequential()\n    model.add(Dense(8,input_dim = 8,kernel_initializer = init,activation = activation_function))\n    model.add(Dropout(0.1))\n    model.add(Dense(4,input_dim = 8,kernel_initializer = init,activation = activation_function))\n    model.add(Dropout(0.1))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n\n# Define the grid search parameters\nactivation_function = ['softmax','relu','tanh','linear']\ninit = ['uniform','normal','zero']\n\n# Make a dictionary of the grid search parameters\nparam_grids = dict(activation_function = activation_function,init = init)\n\n# Build and fit the GridSearchCV\n\ngrid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\ngrid_result = grid.fit(X_standardized,y)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:36:35.252956Z","iopub.execute_input":"2021-12-06T06:36:35.253244Z","iopub.status.idle":"2021-12-06T06:37:20.552408Z","shell.execute_reply.started":"2021-12-06T06:36:35.253219Z","shell.execute_reply":"2021-12-06T06:37:20.551534Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Summarize the results\nprint('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n  print('{},{} with: {}'.format(mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:37:31.419675Z","iopub.execute_input":"2021-12-06T06:37:31.419979Z","iopub.status.idle":"2021-12-06T06:37:31.426472Z","shell.execute_reply.started":"2021-12-06T06:37:31.419954Z","shell.execute_reply":"2021-12-06T06:37:31.425497Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"#### Tuning of Hyperparameter :-Number of Neurons in activation layer","metadata":{}},{"cell_type":"code","source":"# Defining the model\n\ndef create_model(neuron1,neuron2):\n    model = Sequential()\n    model.add(Dense(neuron1,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n\n# Define the grid search parameters\n\nneuron1 = [4,8,16]\nneuron2 = [2,4,8]\n\n# Make a dictionary of the grid search parameters\n\nparam_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n\n# Build and fit the GridSearchCV\n\ngrid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\ngrid_result = grid.fit(X_standardized,y)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:37:51.216514Z","iopub.execute_input":"2021-12-06T06:37:51.216810Z","iopub.status.idle":"2021-12-06T06:38:24.368018Z","shell.execute_reply.started":"2021-12-06T06:37:51.216777Z","shell.execute_reply":"2021-12-06T06:38:24.367012Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Summarize the results\nprint('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n  print('{},{} with: {}'.format(mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:38:31.409264Z","iopub.execute_input":"2021-12-06T06:38:31.409549Z","iopub.status.idle":"2021-12-06T06:38:31.417265Z","shell.execute_reply.started":"2021-12-06T06:38:31.409516Z","shell.execute_reply":"2021-12-06T06:38:31.416109Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"#### Training model with optimum values of Hyperparameters","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\n# Defining the model\n\ndef create_model():\n    model = Sequential()\n    model.add(Dense(16,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(4,input_dim = 16,kernel_initializer = 'uniform',activation = 'tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n\n# Fitting the model\n\nmodel.fit(X_standardized,y)\n\n# Predicting using trained model\n\ny_predict = model.predict(X_standardized)\n\n# Printing the metrics\nprint(accuracy_score(y,y_predict))","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:39:28.356164Z","iopub.execute_input":"2021-12-06T06:39:28.356453Z","iopub.status.idle":"2021-12-06T06:39:29.063715Z","shell.execute_reply.started":"2021-12-06T06:39:28.356428Z","shell.execute_reply":"2021-12-06T06:39:29.062034Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameters all at once","metadata":{}},{"cell_type":"markdown","source":"\nThe hyperparameter optimization was carried out by taking 2 hyperparameters at once. We may have missed the best values. The performance can be further improved by finding the optimum values of hyperparameters all at once given by the code snippet below.\n#### This process is computationally expensive.","metadata":{}},{"cell_type":"code","source":"def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n    model = Sequential()\n    model.add(Dense(neuron1,input_dim = 8,kernel_initializer = init,activation = activation_function))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = learning_rate)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0)\n\n# Define the grid search parameters\n\nbatch_size = [10,20,40]\nepochs = [10,50,100]\nlearning_rate = [0.001,0.01,0.1]\ndropout_rate = [0.0,0.1,0.2]\nactivation_function = ['softmax','relu','tanh','linear']\ninit = ['uniform','normal','zero']\nneuron1 = [4,8,16]\nneuron2 = [2,4,8]\n\n# Make a dictionary of the grid search parameters\n\nparam_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n\n# Build and fit the GridSearchCV\n\ngrid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\ngrid_result = grid.fit(X_standardized,y)\n\n# Summarize the results\nprint('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n  print('{},{} with: {}'.format(mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:40:57.511692Z","iopub.execute_input":"2021-12-06T06:40:57.512014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}