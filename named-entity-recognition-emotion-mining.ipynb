{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Named Entity Recognition","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport string # special operations on strings\nimport spacy # language models\n\nfrom matplotlib.pyplot import imread\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:05.280911Z","iopub.execute_input":"2021-12-08T06:17:05.281607Z","iopub.status.idle":"2021-12-08T06:17:06.172224Z","shell.execute_reply.started":"2021-12-08T06:17:05.281565Z","shell.execute_reply":"2021-12-08T06:17:06.171144Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas\nbook=pd.read_csv(\"../input/apple123/apple.txt\",error_bad_lines=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:06.174999Z","iopub.execute_input":"2021-12-08T06:17:06.175427Z","iopub.status.idle":"2021-12-08T06:17:06.198259Z","shell.execute_reply.started":"2021-12-08T06:17:06.175380Z","shell.execute_reply":"2021-12-08T06:17:06.196848Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"book = [x.strip() for x in book.x] # remove both the leading and the trailing characters\nbook = [x for x in book if x] # removes empty strings, because they are considered in Python as False\nbook[0:10]","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:06.199723Z","iopub.execute_input":"2021-12-08T06:17:06.200045Z","iopub.status.idle":"2021-12-08T06:17:06.215449Z","shell.execute_reply.started":"2021-12-08T06:17:06.200012Z","shell.execute_reply":"2021-12-08T06:17:06.214534Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"##Part Of Speech Tagging\nnlp = spacy.load('en') \n\none_block = book[20]\ndoc_block = nlp(one_block)\nspacy.displacy.render(doc_block, style='ent', jupyter=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:06.216964Z","iopub.execute_input":"2021-12-08T06:17:06.217312Z","iopub.status.idle":"2021-12-08T06:17:07.570492Z","shell.execute_reply.started":"2021-12-08T06:17:06.217279Z","shell.execute_reply":"2021-12-08T06:17:07.569315Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"for token in doc_block[0:20]:\n    print(token, token.pos_)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:07.574677Z","iopub.execute_input":"2021-12-08T06:17:07.574981Z","iopub.status.idle":"2021-12-08T06:17:07.582480Z","shell.execute_reply.started":"2021-12-08T06:17:07.574952Z","shell.execute_reply":"2021-12-08T06:17:07.581476Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Filtering for nouns and verbs only\nnouns_verbs = [token.text for token in doc_block if token.pos_ in ('NOUN', 'VERB')]\nprint(nouns_verbs[5:25])","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:07.590007Z","iopub.execute_input":"2021-12-08T06:17:07.590306Z","iopub.status.idle":"2021-12-08T06:17:07.596538Z","shell.execute_reply.started":"2021-12-08T06:17:07.590278Z","shell.execute_reply":"2021-12-08T06:17:07.595465Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:07.597700Z","iopub.execute_input":"2021-12-08T06:17:07.598048Z","iopub.status.idle":"2021-12-08T06:17:08.552410Z","shell.execute_reply.started":"2021-12-08T06:17:07.598017Z","shell.execute_reply":"2021-12-08T06:17:08.551310Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Counting tokens again\ncv = CountVectorizer()\n\nX = cv.fit_transform(nouns_verbs)\nsum_words = X.sum(axis=0)\nwords_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\nwords_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\nwf_df = pd.DataFrame(words_freq)\nwf_df.columns = ['word', 'count']\n\nwf_df[0:10]","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:08.554039Z","iopub.execute_input":"2021-12-08T06:17:08.554569Z","iopub.status.idle":"2021-12-08T06:17:08.583417Z","shell.execute_reply.started":"2021-12-08T06:17:08.554497Z","shell.execute_reply":"2021-12-08T06:17:08.582635Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"##Visualizing results\n#Barchart for top 10 nouns + verbs\nwf_df[0:10].plot.bar(x='word', figsize=(12,8), title='Top verbs and nouns')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:08.584478Z","iopub.execute_input":"2021-12-08T06:17:08.584925Z","iopub.status.idle":"2021-12-08T06:17:08.867007Z","shell.execute_reply.started":"2021-12-08T06:17:08.584893Z","shell.execute_reply":"2021-12-08T06:17:08.866002Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### Emotion Mining","metadata":{}},{"cell_type":"code","source":"#Sentiment analysis\nafinn = pd.read_csv('../input/afinn123/Afinn.csv', sep=',', encoding='latin-1')\nafinn.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:08.868729Z","iopub.execute_input":"2021-12-08T06:17:08.869406Z","iopub.status.idle":"2021-12-08T06:17:08.888203Z","shell.execute_reply.started":"2021-12-08T06:17:08.869349Z","shell.execute_reply":"2021-12-08T06:17:08.887166Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"afinn.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:08.890183Z","iopub.execute_input":"2021-12-08T06:17:08.890501Z","iopub.status.idle":"2021-12-08T06:17:08.900562Z","shell.execute_reply.started":"2021-12-08T06:17:08.890472Z","shell.execute_reply":"2021-12-08T06:17:08.899329Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from itertools import islice\n\ndef take(n, iterable):\n    \"Return first n items of the iterable as a list\"\n    return list(islice(iterable, n))","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:08.902393Z","iopub.execute_input":"2021-12-08T06:17:08.902933Z","iopub.status.idle":"2021-12-08T06:17:08.914409Z","shell.execute_reply.started":"2021-12-08T06:17:08.902886Z","shell.execute_reply":"2021-12-08T06:17:08.913046Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"affinity_scores = afinn.set_index('word')['value'].to_dict()\ntake(20, affinity_scores.items())","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:08.915888Z","iopub.execute_input":"2021-12-08T06:17:08.916440Z","iopub.status.idle":"2021-12-08T06:17:08.933101Z","shell.execute_reply.started":"2021-12-08T06:17:08.916395Z","shell.execute_reply":"2021-12-08T06:17:08.932147Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport string # special operations on strings\nimport spacy # language models\n\nfrom matplotlib.pyplot import imread\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud\n%matplotlib inline\n\nimport pandas\nbook=pd.read_csv(\"../input/apple123/apple.txt\",error_bad_lines=False)\nbook = [x.strip() for x in book.x] # remove both the leading and the trailing characters\nbook = [x for x in book if x] # removes empty strings, because they are considered in Python as False","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:08.934445Z","iopub.execute_input":"2021-12-08T06:17:08.934925Z","iopub.status.idle":"2021-12-08T06:17:08.952625Z","shell.execute_reply.started":"2021-12-08T06:17:08.934889Z","shell.execute_reply":"2021-12-08T06:17:08.951147Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from nltk import tokenize\nsentences = tokenize.sent_tokenize(\" \".join(book))\nsentences[5:15]","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:08.953770Z","iopub.execute_input":"2021-12-08T06:17:08.954349Z","iopub.status.idle":"2021-12-08T06:17:09.732198Z","shell.execute_reply.started":"2021-12-08T06:17:08.954310Z","shell.execute_reply":"2021-12-08T06:17:09.731298Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"sent_df = pd.DataFrame(sentences, columns=['sentence'])\nsent_df","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:09.733610Z","iopub.execute_input":"2021-12-08T06:17:09.733924Z","iopub.status.idle":"2021-12-08T06:17:09.747335Z","shell.execute_reply.started":"2021-12-08T06:17:09.733894Z","shell.execute_reply":"2021-12-08T06:17:09.746400Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Custom function :score each word in a sentence in lemmatised form, \n#but calculate the score for the whole original sentence.\nnlp = spacy.load('en')\nsentiment_lexicon = affinity_scores\n\ndef calculate_sentiment(text: str = None) -> float:\n    sent_score = 0\n    if text:\n        sentence = nlp(text)\n        for word in sentence:\n            sent_score += sentiment_lexicon.get(word.lemma_, 0)\n    return sent_score","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:09.748779Z","iopub.execute_input":"2021-12-08T06:17:09.749084Z","iopub.status.idle":"2021-12-08T06:17:10.842435Z","shell.execute_reply.started":"2021-12-08T06:17:09.749053Z","shell.execute_reply":"2021-12-08T06:17:10.841559Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# test that it works\ncalculate_sentiment(text = 'very sad')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:10.843681Z","iopub.execute_input":"2021-12-08T06:17:10.843968Z","iopub.status.idle":"2021-12-08T06:17:10.859830Z","shell.execute_reply.started":"2021-12-08T06:17:10.843940Z","shell.execute_reply":"2021-12-08T06:17:10.858342Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"sent_df['sentiment_value'] = sent_df['sentence'].apply(calculate_sentiment)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:10.861198Z","iopub.execute_input":"2021-12-08T06:17:10.861496Z","iopub.status.idle":"2021-12-08T06:17:13.163617Z","shell.execute_reply.started":"2021-12-08T06:17:10.861467Z","shell.execute_reply":"2021-12-08T06:17:13.162341Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# how many words are in the sentence?\nsent_df['word_count'] = sent_df['sentence'].str.split().apply(len)\nsent_df['word_count'].head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:13.165554Z","iopub.execute_input":"2021-12-08T06:17:13.166332Z","iopub.status.idle":"2021-12-08T06:17:13.178578Z","shell.execute_reply.started":"2021-12-08T06:17:13.166281Z","shell.execute_reply":"2021-12-08T06:17:13.177458Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"sent_df.sort_values(by='sentiment_value').tail(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:13.180480Z","iopub.execute_input":"2021-12-08T06:17:13.181254Z","iopub.status.idle":"2021-12-08T06:17:13.197899Z","shell.execute_reply.started":"2021-12-08T06:17:13.181203Z","shell.execute_reply":"2021-12-08T06:17:13.196809Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Sentiment score of the whole review\nsent_df['sentiment_value'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:13.199402Z","iopub.execute_input":"2021-12-08T06:17:13.199858Z","iopub.status.idle":"2021-12-08T06:17:13.211830Z","shell.execute_reply.started":"2021-12-08T06:17:13.199812Z","shell.execute_reply":"2021-12-08T06:17:13.210635Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Sentiment score of the whole review\nsent_df[sent_df['sentiment_value']<=0].head()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:13.213003Z","iopub.execute_input":"2021-12-08T06:17:13.213303Z","iopub.status.idle":"2021-12-08T06:17:13.244922Z","shell.execute_reply.started":"2021-12-08T06:17:13.213273Z","shell.execute_reply":"2021-12-08T06:17:13.244099Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"sent_df[sent_df['sentiment_value']>=20].head()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:13.248760Z","iopub.execute_input":"2021-12-08T06:17:13.249757Z","iopub.status.idle":"2021-12-08T06:17:13.261023Z","shell.execute_reply.started":"2021-12-08T06:17:13.249711Z","shell.execute_reply":"2021-12-08T06:17:13.259667Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"sent_df['index']=range(0,len(sent_df))","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:13.262694Z","iopub.execute_input":"2021-12-08T06:17:13.263236Z","iopub.status.idle":"2021-12-08T06:17:13.268671Z","shell.execute_reply.started":"2021-12-08T06:17:13.263200Z","shell.execute_reply":"2021-12-08T06:17:13.267841Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.distplot(sent_df['sentiment_value'])","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:13.269939Z","iopub.execute_input":"2021-12-08T06:17:13.270442Z","iopub.status.idle":"2021-12-08T06:17:13.617594Z","shell.execute_reply.started":"2021-12-08T06:17:13.270409Z","shell.execute_reply":"2021-12-08T06:17:13.616415Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nsns.lineplot(y='sentiment_value',x='index',data=sent_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:13.619418Z","iopub.execute_input":"2021-12-08T06:17:13.619893Z","iopub.status.idle":"2021-12-08T06:17:13.854970Z","shell.execute_reply.started":"2021-12-08T06:17:13.619846Z","shell.execute_reply":"2021-12-08T06:17:13.853778Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"sent_df.plot.scatter(x='word_count', y='sentiment_value', figsize=(8,8), title='Sentence sentiment value to sentence word count')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:17:13.856482Z","iopub.execute_input":"2021-12-08T06:17:13.857089Z","iopub.status.idle":"2021-12-08T06:17:14.167217Z","shell.execute_reply.started":"2021-12-08T06:17:13.857044Z","shell.execute_reply":"2021-12-08T06:17:14.166310Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}